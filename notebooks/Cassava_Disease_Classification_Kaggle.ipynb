{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cassava_Disease_Classification_Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "190af8f99be34a7890dc22c6fe826306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb8d09a84e004b94821a79e1b03f373a",
              "IPY_MODEL_6eec38f396c346e8b8a23a12717cde59",
              "IPY_MODEL_2a87897632c64b6c95ef80c98f87d060"
            ],
            "layout": "IPY_MODEL_ed634c81ab8d4f1aadd30c57f36d4d57"
          }
        },
        "fb8d09a84e004b94821a79e1b03f373a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6deda8c6f1ed4276be94c53dd916ca79",
            "placeholder": "​",
            "style": "IPY_MODEL_5c810e1bd52f4b4f934d72735aef1368",
            "value": " 28%"
          }
        },
        "6eec38f396c346e8b8a23a12717cde59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bcd8845c39d4660a69b7d1d85948566",
            "max": 196466866,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988cd5e0544642e4a293eeb07c8b7cfb",
            "value": 54910976
          }
        },
        "2a87897632c64b6c95ef80c98f87d060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aff4de17d434ce6b4c7ea49f32bc768",
            "placeholder": "​",
            "style": "IPY_MODEL_008cd83bc0504ae98830afabedfe40a5",
            "value": " 52.4M/187M [02:34&lt;06:39, 354kB/s]"
          }
        },
        "ed634c81ab8d4f1aadd30c57f36d4d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6deda8c6f1ed4276be94c53dd916ca79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c810e1bd52f4b4f934d72735aef1368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bcd8845c39d4660a69b7d1d85948566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988cd5e0544642e4a293eeb07c8b7cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aff4de17d434ce6b4c7ea49f32bc768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008cd83bc0504ae98830afabedfe40a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1bc411f981479f86a3b3d75ec27fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78fa77886c3a417b945b24c823f9e012",
              "IPY_MODEL_00248a8f8c4e42f2bc1ae01afc4b3573"
            ],
            "layout": "IPY_MODEL_29c6036473f74a5daa282ef9c64f3660"
          }
        },
        "78fa77886c3a417b945b24c823f9e012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": " 50%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bb641966e7147df8837be6d8d339d4c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97730dad2ce74cda8b5eee642b09c2ec",
            "value": 1
          }
        },
        "00248a8f8c4e42f2bc1ae01afc4b3573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99fc10ee338e4d00bf4085e5ed2a74a6",
            "placeholder": "​",
            "style": "IPY_MODEL_e05520c6b5994484b4a29ee66895c8dc",
            "value": " 1/2 [1:02:42&lt;1:02:42, 3762.07s/it]"
          }
        },
        "29c6036473f74a5daa282ef9c64f3660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb641966e7147df8837be6d8d339d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97730dad2ce74cda8b5eee642b09c2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "99fc10ee338e4d00bf4085e5ed2a74a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05520c6b5994484b4a29ee66895c8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyI66tHFY_6d"
      },
      "source": [
        "competition name: Cassava Disease Classification \\\\\n",
        "team name: Tihraga \\\\\n",
        "link1: https://www.kaggle.com/c/ammi-2021-convnets/leaderboard \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEqDMXyWwXSq"
      },
      "source": [
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import pprint\n",
        "plt.ion()  \n",
        "!pip install pretrainedmodels >/dev/null 2>&1\n",
        "import pretrainedmodels\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIOG3L54PU9M"
      },
      "source": [
        "# Colab's file access feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8A587fEwou7",
        "outputId": "7b2a1a4e-3544-4854-a874-01b125e347e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "json_file = '/content/drive/MyDrive/cassave/data/kaggle.json'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV8gjwmxPb3Y"
      },
      "source": [
        "# Then move kaggle.json into the folder where the API expects to find it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENF7N3bswsjO"
      },
      "source": [
        "!mkdir -p ~/.kaggle/ && cp '/content/drive/MyDrive/cassave/data/kaggle.json' ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43mqg_vxPg9o"
      },
      "source": [
        "#download data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyUBl14twvS3",
        "outputId": "8002b01a-2eb3-4bff-a192-8db680d61824"
      },
      "source": [
        "!kaggle competitions download -c cassava-disease"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading extraimages.zip to /content\n",
            " 99% 1.03G/1.04G [00:07<00:00, 145MB/s]\n",
            "100% 1.04G/1.04G [00:07<00:00, 155MB/s]\n",
            "Downloading train.zip to /content\n",
            "100% 777M/777M [00:08<00:00, 32.3MB/s]\n",
            "\n",
            "Downloading random.txt to /content\n",
            "  0% 0.00/645k [00:00<?, ?B/s]\n",
            "100% 645k/645k [00:00<00:00, 89.2MB/s]\n",
            "Downloading test.zip to /content\n",
            " 99% 509M/515M [00:10<00:00, 62.6MB/s]\n",
            "100% 515M/515M [00:10<00:00, 51.1MB/s]\n",
            "Downloading sample_submission_file.csv to /content\n",
            "  0% 0.00/83.8k [00:00<?, ?B/s]\n",
            "100% 83.8k/83.8k [00:00<00:00, 79.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUXhbihPksN"
      },
      "source": [
        "#unzip all data :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAL-axulw16T"
      },
      "source": [
        "!unzip -qq train.zip\n",
        "!unzip -qq extraimages.zip\n",
        "!unzip -qq test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3Nc2jsFxKSi"
      },
      "source": [
        "# Exploring Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CweMIjMUxQZk",
        "outputId": "90537b17-516f-4c77-9aeb-2a43f9ba7285"
      },
      "source": [
        "train_path = './train'\n",
        "for classes in os.listdir(train_path):\n",
        "    print('{} : {}'.format(classes, \n",
        "                         len(os.listdir(os.path.join(train_path, classes)))\n",
        "                        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "healthy : 316\n",
            "cgm : 773\n",
            "cmd : 2658\n",
            "cbb : 466\n",
            "cbsd : 1443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEQiqhpz1j20"
      },
      "source": [
        "def get_labels(file_path): \n",
        "    \"\"\"\n",
        "    function to get labels \n",
        "    --\n",
        "    INPUTS:\n",
        "    file_path: (str) the path of the images\n",
        "    --\n",
        "    OUTPUTS: label from the path example (healthy,cgm,cmd,cbsd,cbb)\n",
        "    \"\"\"\n",
        "    dir_name = os.path.dirname(file_path)\n",
        "    split_dir_name = dir_name.split(\"/\")\n",
        "    dir_levels = len(split_dir_name)\n",
        "    label  = split_dir_name[dir_levels - 1]\n",
        "    return(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgvem4EA2Mci"
      },
      "source": [
        "**create image dataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ipc7NQ2K5p"
      },
      "source": [
        "# create image data frame containing image paths & labels\n",
        "from glob import glob\n",
        "imagePaths = glob(\"./train/*/*.*\", recursive=True)\n",
        "images_df = pd.DataFrame(columns=['images', 'labels'])\n",
        "images_df[\"images\"] = imagePaths\n",
        "\n",
        "labels = []\n",
        "for img in imagePaths:\n",
        "    labels.append(get_labels(img))   \n",
        "\n",
        "images_df[\"labels\"] = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oInW9yd13e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "aaf59f29-273e-41ee-faa3-7aaa431d5286"
      },
      "source": [
        "images_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./train/healthy/train-healthy-201.jpg</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./train/healthy/train-healthy-216.jpg</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./train/healthy/train-healthy-240.jpg</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./train/healthy/train-healthy-291.jpg</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./train/healthy/train-healthy-302.jpg</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5651</th>\n",
              "      <td>./train/cbsd/train-cbsd-38.jpg</td>\n",
              "      <td>cbsd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5652</th>\n",
              "      <td>./train/cbsd/train-cbsd-1090.jpg</td>\n",
              "      <td>cbsd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5653</th>\n",
              "      <td>./train/cbsd/train-cbsd-426.jpg</td>\n",
              "      <td>cbsd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5654</th>\n",
              "      <td>./train/cbsd/train-cbsd-623.jpg</td>\n",
              "      <td>cbsd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5655</th>\n",
              "      <td>./train/cbsd/train-cbsd-1179.jpg</td>\n",
              "      <td>cbsd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5656 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     images   labels\n",
              "0     ./train/healthy/train-healthy-201.jpg  healthy\n",
              "1     ./train/healthy/train-healthy-216.jpg  healthy\n",
              "2     ./train/healthy/train-healthy-240.jpg  healthy\n",
              "3     ./train/healthy/train-healthy-291.jpg  healthy\n",
              "4     ./train/healthy/train-healthy-302.jpg  healthy\n",
              "...                                     ...      ...\n",
              "5651         ./train/cbsd/train-cbsd-38.jpg     cbsd\n",
              "5652       ./train/cbsd/train-cbsd-1090.jpg     cbsd\n",
              "5653        ./train/cbsd/train-cbsd-426.jpg     cbsd\n",
              "5654        ./train/cbsd/train-cbsd-623.jpg     cbsd\n",
              "5655       ./train/cbsd/train-cbsd-1179.jpg     cbsd\n",
              "\n",
              "[5656 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufwj6vWZy_cg"
      },
      "source": [
        "# assign different label to extra images \n",
        "from glob import glob\n",
        "extra_imagePaths = glob(\"./extraimages/*.*\", recursive=True)\n",
        "extra_df = pd.DataFrame(columns=['images', 'labels'])\n",
        "extra_df[\"images\"] = extra_imagePaths\n",
        "\n",
        "labels = []\n",
        "for img in extra_imagePaths:\n",
        "    labels.append(-3)   \n",
        "\n",
        "extra_df[\"labels\"] = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0yqlCjk915Mw",
        "outputId": "6b587651-21d2-4ce6-d62e-24e0354ef1ae"
      },
      "source": [
        "extra_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./extraimages/extra-image-6998.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./extraimages/extra-image-13899.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./extraimages/extra-image-10444.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./extraimages/extra-image-457.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./extraimages/extra-image-15112.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12590</th>\n",
              "      <td>./extraimages/extra-image-14440.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12591</th>\n",
              "      <td>./extraimages/extra-image-1876.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12592</th>\n",
              "      <td>./extraimages/extra-image-1081.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12593</th>\n",
              "      <td>./extraimages/extra-image-10710.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12594</th>\n",
              "      <td>./extraimages/extra-image-823.jpg</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12595 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    images  labels\n",
              "0       ./extraimages/extra-image-6998.jpg      -3\n",
              "1      ./extraimages/extra-image-13899.jpg      -3\n",
              "2      ./extraimages/extra-image-10444.jpg      -3\n",
              "3        ./extraimages/extra-image-457.jpg      -3\n",
              "4      ./extraimages/extra-image-15112.jpg      -3\n",
              "...                                    ...     ...\n",
              "12590  ./extraimages/extra-image-14440.jpg      -3\n",
              "12591   ./extraimages/extra-image-1876.jpg      -3\n",
              "12592   ./extraimages/extra-image-1081.jpg      -3\n",
              "12593  ./extraimages/extra-image-10710.jpg      -3\n",
              "12594    ./extraimages/extra-image-823.jpg      -3\n",
              "\n",
              "[12595 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DrbsW2H30nl"
      },
      "source": [
        "**copy the images_df to use it later**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gxeHOKF3kAg"
      },
      "source": [
        "images_df_final = images_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyCFr6uL4EIa"
      },
      "source": [
        "# Label encoding to encode the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79IJ-hef5BAw"
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "images_df[\"labels\"] = labelencoder.fit_transform(images_df[\"labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eEwhJBfo5Q9s",
        "outputId": "efe7b16d-044b-4bb7-9482-0a168541a6e5"
      },
      "source": [
        "images_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./train/healthy/train-healthy-201.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./train/healthy/train-healthy-216.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./train/healthy/train-healthy-240.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./train/healthy/train-healthy-291.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./train/healthy/train-healthy-302.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  images  labels\n",
              "0  ./train/healthy/train-healthy-201.jpg       4\n",
              "1  ./train/healthy/train-healthy-216.jpg       4\n",
              "2  ./train/healthy/train-healthy-240.jpg       4\n",
              "3  ./train/healthy/train-healthy-291.jpg       4\n",
              "4  ./train/healthy/train-healthy-302.jpg       4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDNaME5AJIL-",
        "outputId": "f034ab9e-13bc-4033-eb85-b152738cc6fa"
      },
      "source": [
        "classes = labelencoder.classes_\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cbb' 'cbsd' 'cgm' 'cmd' 'healthy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVOIv8MN0TbU"
      },
      "source": [
        "**Function to set up the seed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DURhA-cxRxT"
      },
      "source": [
        "def seed(seed, cuda):\n",
        "    \"\"\"\n",
        "    function to fix the seed\n",
        "    --\n",
        "    INPUTS:\n",
        "    seed: (int) the seed that we wanted to fix\n",
        "    cuda: (bool) if we are using gpu , then also fix the seed related to cuda \n",
        "    --\n",
        "    OUTPUTS: no output\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhe9TpBy1rSS"
      },
      "source": [
        "**Function to create directories**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1gEOGBUzksl"
      },
      "source": [
        "def create_directories(dir_path):\n",
        "    \"\"\"\n",
        "    function to create directory for checkpoints\n",
        "    --\n",
        "    INPUTS:\n",
        "    dir_path: (str) path of the directory\n",
        "    --\n",
        "    OUTPUTS: no output\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnONXCCPG-C"
      },
      "source": [
        "**Load checkpoint function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc4d5Xk7OrsU"
      },
      "source": [
        "def load_checkpoint(model, optimizer, filename=None):\n",
        "    \"\"\"\n",
        "    function to load the saved checkpoints (to continue the experiment)\n",
        "    --\n",
        "    INPUTS:\n",
        "    model: (model object) \n",
        "    optimizer: (optimizer object)\n",
        "    filename : (str)\n",
        "    --\n",
        "    OUTPUTS: model , optimizer , start epoch\n",
        "    \"\"\" \n",
        "    # Note: Input model & optimizer should be pre-defined. This routine only updates their states. \n",
        "    start_epoch = 0 \n",
        "    if os.path.isfile(filename): \n",
        "        print(\"=> loading checkpoint '{}'\".format(filename)) \n",
        "        checkpoint = torch.load(filename) \n",
        "        start_epoch = checkpoint['epoch'] \n",
        "        model.load_state_dict(checkpoint['state_dict']) \n",
        "        #optimizer.load_state_dict(checkpoint['optimizer']) \n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\" .format(filename,\n",
        "                                                            checkpoint['epoch'])) \n",
        "    else: print(\"=> no checkpoint found at '{}'\".format(filename)) \n",
        "    return model, optimizer, start_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shsaoUiKTXLZ"
      },
      "source": [
        "**filter extra images function (Fixmatch)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0QLD3Q2Ltna"
      },
      "source": [
        "# last update\n",
        "def filter_extra_imgs(threshold = 0.9):\n",
        "    \"\"\"\n",
        "    function to filter the extra images given a threshold\n",
        "    --\n",
        "    INPUTS:\n",
        "    threshold: (int) \n",
        "    --\n",
        "    OUTPUTS: data frame contains the filtered images \n",
        "    \"\"\"\n",
        "  extra_paths = []\n",
        "  peseudo_labels = []\n",
        "\n",
        "  for img_path in extra_df['images']:\n",
        "    img = Image.open(img_path)\n",
        "    img = weak_trans(img)\n",
        "    model_ft.eval()\n",
        "    logits = model_ft(img.unsqueeze_(0).to(device=args.device))\n",
        "    model_ft.train()\n",
        "    if logits.max(-1).values.item() > threshold:\n",
        "      extra_paths.append(img_path)\n",
        "      peseudo_labels.append(torch.argmax(logits).item())\n",
        "\n",
        "  df = pd.DataFrame(columns=['images', 'labels'])\n",
        "  df['images'] = extra_paths\n",
        "  df['labels'] = peseudo_labels\n",
        "\n",
        "  return df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt4gz1FuTeTe"
      },
      "source": [
        "extra_paths = []\n",
        "peseudo_labels = []\n",
        "\n",
        "for i in range(3):\n",
        "  extra_paths.append(extra_df['images'][i])\n",
        "  peseudo_labels.append(-1)\n",
        "\n",
        "df = pd.DataFrame(columns=['images', 'labels'])\n",
        "df['images'] = extra_paths\n",
        "df['labels'] = peseudo_labels\n",
        "\n",
        "\n",
        "images_df_copy = images_df.copy()\n",
        "\n",
        "l_df = pd.concat((images_df_copy, df), axis=0).reset_index( drop =True)\n",
        "l_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_6wKevXPx_z"
      },
      "source": [
        "**configuration for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USqPWZnF0o5k",
        "outputId": "ec2294c3-2a9a-4817-f461-01946e37b532"
      },
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = Namespace(\n",
        "    size = 448,\n",
        "    # Model Hyperparameters\n",
        "    learning_rate = 2e-4,\n",
        "    batch_size = 4,\n",
        "    num_epochs = 20,\n",
        "    valid_num_epochs = 10,\n",
        "    momentum=0.9,\n",
        "\n",
        "    # Data Parameters\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]),\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]),\n",
        "    validation_split = .1,\n",
        "    shuffle_dataset = True,\n",
        "    num_folds=5,\n",
        "\n",
        "    seed= 0,\n",
        "\n",
        "    # Paths\n",
        "    save_dir = \"/content/drive/MyDrive/kaggle/cassave/\",\n",
        "    train_path = \"./train\",\n",
        "    test_path = \"./test/0\",\n",
        "\n",
        "    # Runtime hyper parameter\n",
        "    cuda=True,\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed(args.seed, args.cuda)\n",
        "\n",
        "# create directories\n",
        "create_directories(args.save_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9OhFJ5f1MyQ",
        "outputId": "6ef8a893-6063-4b80-903d-2d188d4cc309"
      },
      "source": [
        "%env TORCH_HOME=$args.save_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TORCH_HOME=/content/drive/MyDrive/kaggle/cassave/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vCiGJYg6bGX"
      },
      "source": [
        "# plot the training data for more clarification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "PRO8EC6C3-DC",
        "outputId": "c6fd30d7-c1ce-4198-dc79-e7031365b6af"
      },
      "source": [
        "images_df.labels.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1q9nZ0n6uEJ"
      },
      "source": [
        "we noticed that class 3 has the highest number of data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9g_mGEf68_g"
      },
      "source": [
        "**order the classes based on the number of images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHzpdw5r6i4E",
        "outputId": "3a7f403c-0612-4e7e-c99e-7d27053942ed"
      },
      "source": [
        "images_df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    2658\n",
              "1    1443\n",
              "2     773\n",
              "0     466\n",
              "4     316\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH_4q4xzTkmm"
      },
      "source": [
        "# Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_kpYPBcN9_T"
      },
      "source": [
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, df_data, transform=None):\n",
        "        super().__init__()\n",
        "        self.df = df_data.values\n",
        "        \n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path, label = self.df[index]\n",
        "        \n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J4nfu1t372h"
      },
      "source": [
        "class extra_CassavaDataset(Dataset):\n",
        "    def __init__(self, df_data, train_transform=None, strong_trans=None):\n",
        "        super().__init__()\n",
        "        self.df = df_data.values\n",
        "        \n",
        "        self.train_transform = train_transform\n",
        "        self.strong_trans = strong_trans\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path, label = self.df[index]\n",
        "        \n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if img_path.split('/')[1] == 'train':\n",
        "          if self.train_transform is not None:\n",
        "              image = self.train_transform(image)\n",
        "        else:\n",
        "          if self.strong_trans is not None:\n",
        "              image = self.strong_trans(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8yVZvRIO7Wy"
      },
      "source": [
        "# Set of transformations :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fKfrU8ZF0g_",
        "outputId": "af407361-e781-42b8-be9c-02cf99126f26"
      },
      "source": [
        "!pip install randaugment\n",
        "from randaugment import RandAugment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting randaugment\n",
            "  Downloading randaugment-1.0.2-py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: randaugment\n",
            "Successfully installed randaugment-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAwhfFV-OIrA"
      },
      "source": [
        "train_trans = T.Compose([\n",
        "        T.RandomResizedCrop(args.size),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomVerticalFlip(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(args.mean, args.std)\n",
        "    ])\n",
        "\n",
        "val_trans = T.Compose([\n",
        "        T.Resize(500),\n",
        "        T.CenterCrop(args.size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(args.mean, args.std)\n",
        "    ])\n",
        "\n",
        "test_trans = T.Compose([\n",
        "        T.Resize(500),\n",
        "        T.CenterCrop(args.size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(args.mean, args.std)\n",
        "    ])\n",
        "\n",
        "\n",
        "weak_trans =  T.Compose([\n",
        "        T.Resize(448),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.RandomCrop(size=448, \n",
        "                      padding=int(448*0.125), \n",
        "                      padding_mode='reflect'),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(args.mean, args.std)\n",
        "    ])\n",
        "\n",
        "\n",
        "strong_trans =  T.Compose([\n",
        "        T.Resize(448),\n",
        "        # T.RandomHorizontalFlip(p=0.5),\n",
        "        T.RandomCrop(size=448, \n",
        "                      padding=int(448*0.125), \n",
        "                      padding_mode='reflect'),\n",
        "      \n",
        "        # T.RandomErasing(p=1, \n",
        "        #                 ratio=(1, 1), \n",
        "        #                 scale=(0.01, 0.01), \n",
        "        #                 value=127),\n",
        "        RandAugment(),\n",
        "        \n",
        "        T.ToTensor(),\n",
        "        T.Normalize(args.mean, args.std)    \n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdS4FKtTKFa"
      },
      "source": [
        "#Models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpLLDne-QUBX"
      },
      "source": [
        "def resnet50(pretrained=True):\n",
        "    \"\"\"\n",
        "    function to get pretrained model resnet50 \n",
        "    --\n",
        "    INPUTS:\n",
        "    pretrained: (bool) \n",
        "    --\n",
        "    OUTPUTS: model\n",
        "    \"\"\" \n",
        "    model = models.resnet50(pretrained=pretrained)\n",
        "    return model\n",
        "\n",
        "def se_resnext50_32x4d(pretrained=True):\n",
        "    \"\"\"\n",
        "    function to get pretrained model resnext50_32x4d\n",
        "    --\n",
        "    INPUTS:\n",
        "    pretrained: (bool) \n",
        "    --\n",
        "    OUTPUTS: model\n",
        "    \"\"\" \n",
        "    pretrained = 'imagenet' if pretrained else None\n",
        "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
        "    return model\n",
        "\n",
        "def se_resnext101_32x4d(pretrained=True):\n",
        "    \"\"\"\n",
        "    function to get pretrained model resnext101_32x4d\n",
        "    --\n",
        "    INPUTS:\n",
        "    pretrained: (bool) \n",
        "    --\n",
        "    OUTPUTS: model\n",
        "    \"\"\" \n",
        "    pretrained = 'imagenet' if pretrained else None\n",
        "    model = pretrainedmodels.se_resnext101_32x4d(pretrained=pretrained)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhMeJz_BQlzn"
      },
      "source": [
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, model, num_classes=1000):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.backbone = model\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "        self.conv_last = nn.Conv2d(512, num_classes, 1)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "\n",
        "        x = self.backbone.avgpool(x)\n",
        "        x = self.dropout(x)  \n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiJb6zdmQ1uy"
      },
      "source": [
        "class SEResnext101(nn.Module): \n",
        "    def __init__(self, model, num_classes=1000): \n",
        "        super().__init__() \n",
        "        self.backbone = model \n",
        "        self.dropout = nn.Dropout(0.5) \n",
        "        self.fc = nn.Linear(2048, 5) \n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "    def forward(self, x): \n",
        "        x = self.backbone.layer0(x) \n",
        "        x = self.backbone.layer1(x) \n",
        "        x = self.backbone.layer2(x) \n",
        "        x = self.backbone.layer3(x) \n",
        "        x = self.backbone.layer4(x) \n",
        "        x = self.avg_pool(x)\n",
        "        x = self.dropout(x)  \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-H7e_QOSCMy"
      },
      "source": [
        "def get_model(model_name = 'se_resnext101_32x4d'):\n",
        "    \"\"\"\n",
        "    function to get model given the model name and adopted to cassava classification task\n",
        "    --\n",
        "    INPUTS:\n",
        "    model_name: (str) \n",
        "    --\n",
        "    OUTPUTS: model\n",
        "    \"\"\" \n",
        "    if model_name == 'se_resnext101_32x4d':\n",
        "        base_model = se_resnext101_32x4d(pretrained=True)\n",
        "        model_ft = SEResnext101(base_model, 5)\n",
        "\n",
        "    elif model_name == 'se_resnext50_32x4d':\n",
        "        model_ft = se_resnext50_32x4d(pretrained=False)\n",
        "        model_ft.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        num_ftrs = model_ft.last_linear.in_features\n",
        "        model_ft.last_linear = torch.nn.Linear(num_ftrs, 5)\n",
        "\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = models.resnet50(pretrained=True)\n",
        "        model_ft = ResNet50(base_model, 5)\n",
        "\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "    model_ft = model_ft.to(args.device)\n",
        "    return model_ft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "190af8f99be34a7890dc22c6fe826306",
            "fb8d09a84e004b94821a79e1b03f373a",
            "6eec38f396c346e8b8a23a12717cde59",
            "2a87897632c64b6c95ef80c98f87d060",
            "ed634c81ab8d4f1aadd30c57f36d4d57",
            "6deda8c6f1ed4276be94c53dd916ca79",
            "5c810e1bd52f4b4f934d72735aef1368",
            "9bcd8845c39d4660a69b7d1d85948566",
            "988cd5e0544642e4a293eeb07c8b7cfb",
            "6aff4de17d434ce6b4c7ea49f32bc768",
            "008cd83bc0504ae98830afabedfe40a5"
          ]
        },
        "id": "tKQTKK-4SKA9",
        "outputId": "78687733-54fc-4a90-e774-80cb2cb72282"
      },
      "source": [
        "model_ft = get_model(model_name = 'se_resnext101_32x4d')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), \n",
        "                         lr=args.learning_rate, \n",
        "                         momentum=args.momentum)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext101_32x4d-3b2fe3d8.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "190af8f99be34a7890dc22c6fe826306",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/187M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzN3MMsjUIHw"
      },
      "source": [
        "# Training :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woJoRZF9S9q6"
      },
      "source": [
        "**Function to train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4bib4D9SPWp"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    \"\"\"\n",
        "    function to train the model\n",
        "    --\n",
        "    INPUTS:\n",
        "    model: (model object) \n",
        "    criterion : criterion for the loss\n",
        "    optimizer : (optimizer object)\n",
        "    scheduler : (scheduler object) to schedule the learning rate\n",
        "    num_epochs: (int) number of epoch to train \n",
        "    --\n",
        "    OUTPUTS: trained model\n",
        "    \"\"\" \n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(args.device)\n",
        "                labels = labels.to(args.device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                 # \n",
        "                state = {'epoch': epoch,'state_dict': model.state_dict(), \n",
        "                            'optimizer': 'optimizer_ft.state_dict()', \n",
        "                             'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "                create_directories(args.save_dir)\n",
        "                full_model_path = args.save_dir+'/model_state_fixmatch.tar'\n",
        "                #full_model_path = saved_dir+'model_state.tar'\n",
        "                torch.save(state, full_model_path)\n",
        "                #\n",
        "                \n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhWlbkDXVYAv"
      },
      "source": [
        "# Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdE5H7vXTWAi"
      },
      "source": [
        "st_kfold = StratifiedKFold(n_splits=args.num_folds, shuffle=True, random_state=args.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbr9gYQLTW82"
      },
      "source": [
        "#### UN comment this ####\n",
        "\n",
        "\n",
        "fold = 0\n",
        "for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "    train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "    train_dataset = CassavaDataset(df_data=train, transform=train_trans)\n",
        "    valid_dataset = CassavaDataset(df_data=val,transform=val_trans)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset, \n",
        "                              batch_size=args.batch_size, \n",
        "                              shuffle=True, \n",
        "                              num_workers=4,\n",
        "                              )\n",
        "    valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                              batch_size=args.batch_size, \n",
        "                              shuffle=False, \n",
        "                              num_workers=4,\n",
        "                              )\n",
        "\n",
        "    dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "    \n",
        "    dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "    print(dataset_sizes)\n",
        "    if fold == 1:\n",
        "\n",
        "        saved_dir = args.save_dir+str(fold)+'/'\n",
        "\n",
        "        print(f'Starting CV for Fold {fold}')\n",
        "\n",
        "        model_ft = train_model(model_ft, criterion, \n",
        "                            optimizer_ft, \n",
        "                            exp_lr_scheduler, \n",
        "                            num_epochs=args.num_epochs,)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "\n",
        "state = {'epoch': 2,'state_dict': model_ft.state_dict(), \n",
        "                            'optimizer': 'optimizer_ft.state_dict()', \n",
        "                             'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "create_directories(saved_dir)\n",
        "full_model_path = args.save_dir+'/model_state.tar'\n",
        "#full_model_path = saved_dir+'model_state.tar'\n",
        "torch.save(state, full_model_path)\n",
        "print('Cross Validation Done ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guby-F8LTmpq"
      },
      "source": [
        "full_model_path = args.save_dir+'model_state.tar'\n",
        "final_model, optimizer, _ = load_checkpoint(model_ft, \n",
        "                                            optimizer_ft, \n",
        "                                            filename=full_model_path,\n",
        "                                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6RmnlNqpVTqE",
        "outputId": "06c5a08b-1a58-47d0-c6c0-4a3c4883c8ec"
      },
      "source": [
        "sample_sub_file_path = 'sample_submission_file.csv'\n",
        "df_test = pd.read_csv(sample_sub_file_path)\n",
        "test_data = df_test['Id']\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cbsd</td>\n",
              "      <td>test-img-0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cbb</td>\n",
              "      <td>test-img-2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cmd</td>\n",
              "      <td>test-img-3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cbsd</td>\n",
              "      <td>test-img-4.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category              Id\n",
              "0     cbsd  test-img-0.jpg\n",
              "1      cmd  test-img-1.jpg\n",
              "2      cbb  test-img-2.jpg\n",
              "3      cmd  test-img-3.jpg\n",
              "4     cbsd  test-img-4.jpg"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dagnGucvWSuU"
      },
      "source": [
        "# Testing :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUkdiCu4Ve6Q"
      },
      "source": [
        "class CassavaTestDataset(Dataset):\n",
        "    def __init__(self, df_data, transform=None, tta=False, tta_idx=0, data_path='./test/0/'):\n",
        "        super().__init__()\n",
        "        self.df = df_data.values\n",
        "        self.transform = transform\n",
        "        self.tta=tta\n",
        "        self.tta_idx = tta_idx\n",
        "        self.data_path = data_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.df[index]\n",
        "        img_path = os.path.join(self.data_path, image_name)\n",
        "        image = Image.open(img_path)\n",
        "        if self.tta:\n",
        "           image = crop_image(image, crop_idx=self.tta_idx)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_LWneoFWuLz"
      },
      "source": [
        "def crop_image(im, crop_idx):\n",
        "    \"\"\"\n",
        "    function to perform image croping and flipping (image augmentation)\n",
        "    --\n",
        "    INPUTS:\n",
        "    im: (image object) \n",
        "    crop_idx : the index of cropping \n",
        "    --\n",
        "    OUTPUTS: augmented image\n",
        "    \"\"\" \n",
        "    w, h = im.size\n",
        "    if crop_idx == 0:\n",
        "        im = im.crop((0, 0, int(w*0.9), int(h*0.9))) # top left\n",
        "    elif crop_idx == 1:\n",
        "        im = im.crop((int(w*0.1), 0, w, int(h*0.9))) # top right\n",
        "    elif crop_idx == 2:\n",
        "        im = im.crop((int(w*0.05), int(h*0.05), w-int(w*0.05), h-int(h*0.05))) # center\n",
        "    elif crop_idx == 3:\n",
        "        im = im.crop((0, int(h*0.1), w-int(w*0.1), h)) # bottom left\n",
        "    elif crop_idx == 4:\n",
        "        im = im.crop((int(w*0.1), int(h*0.1), w, h)) # bottom right\n",
        "    elif crop_idx == 5:\n",
        "        im = im.crop((0, 0, int(w*0.9), int(h*0.9))) \n",
        "        im = im.transpose(Image.FLIP_LEFT_RIGHT) # top left and HFlip\n",
        "    elif crop_idx == 6:\n",
        "        im = im.crop((int(w*0.1), 0, w, int(h*0.9)))\n",
        "        im = im.transpose(Image.FLIP_LEFT_RIGHT) # top right and HFlip\n",
        "    elif crop_idx == 7:\n",
        "        im = im.crop((int(w*0.05), int(h*0.05), w-int(w*0.05), h-int(h*0.05)))\n",
        "        im = im.transpose(Image.FLIP_LEFT_RIGHT) # center and HFlip\n",
        "    elif crop_idx == 8:\n",
        "        im = im.crop((0, int(h*0.1), w-int(w*0.1), h))\n",
        "        im = im.transpose(Image.FLIP_LEFT_RIGHT) # bottom left and HFlip\n",
        "    elif crop_idx == 9:\n",
        "        im = im.crop((int(w*0.1), int(h*0.1), w, h))\n",
        "        im = im.transpose(Image.FLIP_LEFT_RIGHT) # bottom right and HFlip\n",
        "    return im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQs-6xmWyN7"
      },
      "source": [
        "def predict_without_tta(model, transform, test_data, data_path='./test/0/'):\n",
        "    \"\"\"\n",
        "    function to get the predictions without test time augmentation (this function create csv file for submission)\n",
        "    --\n",
        "    INPUTS:\n",
        "    model: (model object) \n",
        "    transform : (transform object)\n",
        "    test_data : (data frame) containing the category of the image and the path\n",
        "    data_path : (str) path for the test data\n",
        "    --\n",
        "    OUTPUTS: No output\n",
        "    \"\"\" \n",
        "    since = time.time()\n",
        "    \n",
        "    test_dataset = CassavaTestDataset(test_data, transform=transform, data_path=data_path)\n",
        "    test_loader = DataLoader(test_dataset, shuffle=False, batch_size=args.batch_size//2)\n",
        "\n",
        "    model.eval()\n",
        "    results = []\n",
        "    threshold = 4\n",
        "    print('Inferencing ...')\n",
        "    for images, image_names in test_loader:\n",
        "        images = images.to(args.device)\n",
        "        output = model(images)\n",
        "        preds = torch.argmax(output, dim=-1)\n",
        "        preds = preds.cpu().detach().numpy()\n",
        "       \n",
        "        for pred, image_name in zip(preds, image_names):\n",
        "            \n",
        "            results.append({'Id':image_name, 'Category': classes[pred]})\n",
        "            \n",
        "\n",
        "    df = pd.DataFrame(results, columns=['Category', 'Id'])\n",
        "    df.to_csv('sub.csv', index=False)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjZmF2pfXYLK"
      },
      "source": [
        "predict_without_tta(model=model_ft, \n",
        "          transform=test_trans, \n",
        "          test_data=test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycfXTQPHX_UV"
      },
      "source": [
        "def predict_with_tta(model, transform, test_data, num_of_tta=10, data_path='./test/0/'):  \n",
        "    \"\"\"\n",
        "    function to get the predictions using test time augmentation (this function create csv file for submission)\n",
        "    --\n",
        "    INPUTS:\n",
        "    model: (model object) \n",
        "    transform : (transform object)\n",
        "    test_data : (data frame) containing the category of the image and the path\n",
        "    data_path : (str) path for the test data\n",
        "    num_of_tta : (int) number of augmentations \n",
        "    --\n",
        "    OUTPUTS: No output\n",
        "    \"\"\" \n",
        "    since = time.time()\n",
        "\n",
        "    assert num_of_tta <= 10, \"TTA number must not be more than 10\"\n",
        "\n",
        "    TTA10 = []\n",
        "    results = []\n",
        "    print(f'Inferencing with {num_of_tta} TTA ...')\n",
        "\n",
        "    for tta_idx in range(num_of_tta):\n",
        "        test_dataset = CassavaTestDataset(test_data, transform=transform, tta=True, tta_idx=tta_idx, data_path=data_path )\n",
        "        \n",
        "        test_loader = DataLoader(test_dataset, shuffle=False, batch_size=args.batch_size//2, num_workers=0)\n",
        "        model.eval()\n",
        "\n",
        "        names2probs = {}\n",
        "        for images, image_names in test_loader:\n",
        "            images = images.to(args.device)\n",
        "            output = model(images)\n",
        "\n",
        "            probs = F.softmax(output, dim=-1)\n",
        "            probs = probs.cpu().detach().numpy()\n",
        "            for prob, image_name in zip(probs, image_names):\n",
        "                names2probs[image_name] = prob\n",
        "\n",
        "        TTA10.append(names2probs)\n",
        "\n",
        "    for im_name in TTA10[0]:\n",
        "        # Find average of all prediction probabilities for each class\n",
        "        avg_prob = torch.zeros(5)\n",
        "        for prob_idx in range(num_of_tta):\n",
        "            avg_prob += TTA10[prob_idx][im_name]\n",
        "\n",
        "        avg_prob = avg_prob/num_of_tta\n",
        "        pred = torch.argmax(avg_prob)\n",
        "        pred = pred.cpu().detach().numpy()\n",
        "\n",
        "        results.append({'Id':im_name, 'Category':classes[pred]})\n",
        "\n",
        "    df = pd.DataFrame(results, columns=['Category', 'Id'])\n",
        "    df.to_csv('sub_tta.csv', index=False)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFteD21VZXwI"
      },
      "source": [
        "# Dealing with Extra Images :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP0aJfTSyWdj"
      },
      "source": [
        "\n",
        "# Based on https://github.com/peimengsui/semi_supervised_mnist\n",
        "# from tqdm import tqdm_notebook\n",
        "\n",
        "T1 = 100\n",
        "T2 = 700\n",
        "af = 3\n",
        "\n",
        "def alpha_weight(step):\n",
        "    if step < T1:\n",
        "        return 0.0\n",
        "    elif step > T2:\n",
        "        return af\n",
        "    else:\n",
        "         return ((step-T1) / (T2-T1))*af\n",
        "        \n",
        "\n",
        "def semisup_train(model, unlabeled_loader,criterion, optimizer , scheduler):\n",
        "  # optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "  EPOCHS = 2\n",
        "  \n",
        "  # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
        "  # This helps the model converge faster\n",
        "  step = 100 \n",
        "  main_epoch = 0\n",
        "  \n",
        "  model.train()\n",
        "  for epoch in tqdm.notebook.tqdm(range(EPOCHS)):\n",
        "    print('epoch=', epoch, 'of unlabled data!')\n",
        "    for batch_idx, x_unlabeled_tuple in enumerate(unlabeled_loader):\n",
        "\n",
        "      x_unlabeled = x_unlabeled_tuple[0]\n",
        "        \n",
        "        \n",
        "      # Forward Pass to get the pseudo labels\n",
        "      x_unlabeled = x_unlabeled.cuda()\n",
        "      model.eval()\n",
        "      output_unlabeled = model(x_unlabeled)\n",
        "      _, pseudo_labeled = torch.max(output_unlabeled, 1)\n",
        "      model.train()          \n",
        "      \n",
        "      # Now calculate the unlabeled loss using the pseudo label\n",
        "      output = model(x_unlabeled)\n",
        "      unlabeled_loss = alpha_weight(step) * F.nll_loss(output, pseudo_labeled)   \n",
        "      \n",
        "      # Backpropogate\n",
        "      optimizer.zero_grad()\n",
        "      unlabeled_loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      \n",
        "      # For every 50 batches train one epoch on labeled data \n",
        "      if batch_idx % 629 == 0:\n",
        "        print('main epoch=',  main_epoch)\n",
        "\n",
        "     \n",
        "        # # Normal training procedure\n",
        "        # for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        #     X_batch = X_batch.cuda()\n",
        "        #     y_batch = y_batch.cuda()\n",
        "        #     output = model(X_batch)\n",
        "        #     labeled_loss = F.nll_loss(output, y_batch)\n",
        "\n",
        "        #     optimizer.zero_grad()\n",
        "        #     labeled_loss.backward()\n",
        "        #     optimizer.step()\n",
        "        \n",
        "\n",
        "        fold = 0\n",
        "        for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "          print('inside')\n",
        "\n",
        "          train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "          train_dataset = CassavaDataset(df_data=train, transform=train_trans)\n",
        "          valid_dataset = CassavaDataset(df_data=val,transform=val_trans)\n",
        "\n",
        "          train_loader = DataLoader(dataset = train_dataset, \n",
        "                                    batch_size=args.batch_size, \n",
        "                                    shuffle=True, \n",
        "                                    num_workers=2,\n",
        "                                    )\n",
        "          valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                                    batch_size=args.batch_size, \n",
        "                                    shuffle=False, \n",
        "                                    num_workers=2,\n",
        "                                    )\n",
        "\n",
        "          dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "          \n",
        "          dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "\n",
        "          if fold == 1:\n",
        "            model = train_model(model, criterion, \n",
        "                            optimizer_ft, \n",
        "                            exp_lr_scheduler, \n",
        "                            num_epochs=1,)\n",
        "          fold += 1\n",
        "    \n",
        "        # Now we increment step by 1\n",
        "        step += 1\n",
        "        main_epoch += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIuol0hsyWhy",
        "outputId": "da069753-59e7-42f3-a774-616d52664802"
      },
      "source": [
        "\n",
        "fold = 0\n",
        "for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "    train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "    train_dataset = CassavaDataset(df_data=train, transform=train_trans)\n",
        "    valid_dataset = CassavaDataset(df_data=val,transform=val_trans)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset, \n",
        "                              batch_size=args.batch_size, \n",
        "                              shuffle=True, \n",
        "                              num_workers=2,\n",
        "                              )\n",
        "    valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                              batch_size=args.batch_size, \n",
        "                              shuffle=False, \n",
        "                              num_workers=2,\n",
        "                              )\n",
        "\n",
        "    dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "    \n",
        "    dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "    print(dataset_sizes)\n",
        "    if fold == 1:\n",
        "\n",
        "      saved_dir = args.save_dir+str(fold)+'/'\n",
        "\n",
        "      print(f'Starting CV for Fold {fold}')\n",
        "\n",
        "      model_ft = train_model(model_ft, criterion, \n",
        "                          optimizer_ft, \n",
        "                          exp_lr_scheduler, \n",
        "                          num_epochs=1,)\n",
        "\n",
        "    fold += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': 4524, 'val': 1132}\n",
            "{'train': 4525, 'val': 1131}\n",
            "Starting CV for Fold 1\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 1.0419 Acc: 0.5996\n",
            "val Loss: 0.7093 Acc: 0.7392\n",
            "\n",
            "Training complete in 10m 2s\n",
            "Best val Acc: 0.739169\n",
            "{'train': 4525, 'val': 1131}\n",
            "{'train': 4525, 'val': 1131}\n",
            "{'train': 4525, 'val': 1131}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "aa1bc411f981479f86a3b3d75ec27fd0",
            "78fa77886c3a417b945b24c823f9e012",
            "00248a8f8c4e42f2bc1ae01afc4b3573",
            "29c6036473f74a5daa282ef9c64f3660",
            "5bb641966e7147df8837be6d8d339d4c",
            "97730dad2ce74cda8b5eee642b09c2ec",
            "99fc10ee338e4d00bf4085e5ed2a74a6",
            "e05520c6b5994484b4a29ee66895c8dc"
          ]
        },
        "id": "-leck-tSE8d4",
        "outputId": "75c38311-f3ea-4b74-b84b-e509c4beb925"
      },
      "source": [
        "\n",
        "# Based on https://github.com/peimengsui/semi_supervised_mnist\n",
        "import tqdm\n",
        "T1 = 100\n",
        "T2 = 700\n",
        "af = 3\n",
        "\n",
        "extra_dataset = extra_CassavaDataset(df_data=extra_df, \n",
        "                               transform=train_trans)\n",
        "extra_loader = DataLoader(dataset = extra_dataset, \n",
        "                          batch_size=args.batch_size, \n",
        "                          shuffle=True, \n",
        "                          num_workers=2,\n",
        "                          )\n",
        "\n",
        "semisup_train(model_ft, extra_loader, criterion ,  optimizer_ft, exp_lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa1bc411f981479f86a3b3d75ec27fd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch= 0 of unlabled data!\n",
            "main epoch= 0\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3931 Acc: 0.8690\n",
            "val Loss: 0.2201 Acc: 0.9310\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.931034\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 1\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3709 Acc: 0.8815\n",
            "val Loss: 0.2266 Acc: 0.9284\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.928382\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 2\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3902 Acc: 0.8694\n",
            "val Loss: 0.2020 Acc: 0.9319\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.931919\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 3\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3795 Acc: 0.8787\n",
            "val Loss: 0.2042 Acc: 0.9363\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.936340\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 4\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3765 Acc: 0.8773\n",
            "val Loss: 0.2014 Acc: 0.9337\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.933687\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 5\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3723 Acc: 0.8738\n",
            "val Loss: 0.2310 Acc: 0.9204\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.920424\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "epoch= 1 of unlabled data!\n",
            "main epoch= 6\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3701 Acc: 0.8809\n",
            "val Loss: 0.2357 Acc: 0.9142\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.914235\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 7\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3656 Acc: 0.8769\n",
            "val Loss: 0.2390 Acc: 0.9222\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.922193\n",
            "inside\n",
            "inside\n",
            "inside\n",
            "main epoch= 8\n",
            "inside\n",
            "inside\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 0.3727 Acc: 0.8756\n",
            "val Loss: 0.2139 Acc: 0.9275\n",
            "\n",
            "Training complete in 6m 48s\n",
            "Best val Acc: 0.927498\n",
            "inside\n",
            "inside\n",
            "inside\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZRH8NKxTtu"
      },
      "source": [
        "# Fix Match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c5Z1praxW0E"
      },
      "source": [
        "def fix_match(model, criterion, optimizer , scheduler, num_of_epochs = 2, threshold = 0.9):\n",
        "\n",
        "  # gc.collect()\n",
        "  # torch.cuda.empty_cache()\n",
        "  # optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "  EPOCHS = num_of_epochs\n",
        "  \n",
        "  # Instead of using current epoch we use a \"step\" variable to calculate alpha_weight\n",
        "  # This helps the model converge faster\n",
        "  \n",
        "  model.train()\n",
        "  for epoch in tqdm.notebook.tqdm(range(EPOCHS)):\n",
        "    print('epoch=', epoch, '!!!')\n",
        "\n",
        "    for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "\n",
        "      train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "      valid_dataset = CassavaDataset(df_data=val,transform=val_trans)\n",
        "      valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                                batch_size=4, \n",
        "                                shuffle=False, \n",
        "                                num_workers=2,\n",
        "                                )\n",
        "\n",
        "      l_train_dataset = CassavaDataset(df_data=train, transform=train_trans)\n",
        "      l_train_loader = DataLoader(dataset = l_train_dataset, \n",
        "                                batch_size=4, \n",
        "                                shuffle=True, \n",
        "                                num_workers=2,\n",
        "                                )\n",
        "      \n",
        "\n",
        "      u_train_dataset_weak = extra_CassavaDataset(df_data=extra_df, transform=weak_trans)\n",
        "      u_train_loader_weak = DataLoader(dataset = u_train_dataset_weak, \n",
        "                                batch_size=11, \n",
        "                                shuffle=True, \n",
        "                                num_workers=2,\n",
        "                                )\n",
        "\n",
        "      u_train_dataset_strong = extra_CassavaDataset(df_data=extra_df, transform=strong_trans)\n",
        "      u_train_loader_strong = DataLoader(dataset = u_train_dataset_strong, \n",
        "                                batch_size=11, \n",
        "                                shuffle=True, \n",
        "                                num_workers=2,\n",
        "                                )\n",
        "      \n",
        "      for t1, t2, t3 in zip(l_train_loader, u_train_loader_weak, u_train_loader_strong):\n",
        "        labeled_imgs, labels = t1[:][0], t1[:][1]\n",
        "        weak_imgs, strong_imgs = t2[:][0], t3[:][0]\n",
        "\n",
        "        model.eval()\n",
        "        pseudo_labeled = model(weak_imgs.to(device=args.device))\n",
        "\n",
        "        print(pseudo_labeled.shape)\n",
        "\n",
        "        break\n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1t4pg4zxW2z"
      },
      "source": [
        "import tqdm\n",
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "fix_match(model_ft, criterion, optimizer_ft , exp_lr_scheduler, num_of_epochs = 2, threshold = 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKvEnwsJg_oq"
      },
      "source": [
        "l_train_dataset = CassavaDataset(df_data=images_df, transform=train_trans)\n",
        "l_train_loader = DataLoader(dataset = l_train_dataset, \n",
        "                          batch_size=4, \n",
        "                          shuffle=True, \n",
        "                          num_workers=2,\n",
        "                          )\n",
        "\n",
        "u_train_dataset_weak = extra_CassavaDataset(df_data=extra_df, transform=weak_trans)\n",
        "u_train_loader_weak = DataLoader(dataset = u_train_dataset_weak, \n",
        "                          batch_size=11, \n",
        "                          shuffle=True, \n",
        "                          num_workers=2,\n",
        "                          )\n",
        "\n",
        "u_train_dataset_strong = extra_CassavaDataset(df_data=extra_df, transform=strong_trans)\n",
        "u_train_loader_strong = DataLoader(dataset = u_train_dataset_strong, \n",
        "                          batch_size=11, \n",
        "                          shuffle=True, \n",
        "                          num_workers=2,\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zxpSIHnWXJZ"
      },
      "source": [
        "# last"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AXWRxuzWiZ-"
      },
      "source": [
        "# train the model for 5 echocks\n",
        "\n",
        "for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "    train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "    train_dataset = CassavaDataset(df_data=train, transform=train_trans)\n",
        "    valid_dataset = CassavaDataset(df_data=val,transform=val_trans)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset, \n",
        "                              batch_size=args.batch_size, \n",
        "                              shuffle=True, \n",
        "                              num_workers=2,\n",
        "                              )\n",
        "    valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                              batch_size=args.batch_size, \n",
        "                              shuffle=False, \n",
        "                              num_workers=2,\n",
        "                              )\n",
        "\n",
        "    dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "    \n",
        "    dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "\n",
        "\n",
        "    model_ft = train_model(model_ft, criterion, \n",
        "                          optimizer_ft, \n",
        "                          exp_lr_scheduler, \n",
        "                          num_epochs=5,)\n",
        "\n",
        "    break\n",
        "\n",
        "\n",
        "# \n",
        "state = {'epoch': epoch,'state_dict': model_ft.state_dict(), \n",
        "            'optimizer': 'optimizer_ft.state_dict()', \n",
        "              'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "create_directories(args.save_dir)\n",
        "full_model_path = args.save_dir+'/model_state_trained_labeled_5_epochs.tar'\n",
        "#full_model_path = saved_dir+'model_state.tar'\n",
        "torch.save(state, full_model_path)\n",
        "#\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfsrXY4ON02n"
      },
      "source": [
        "# \n",
        "state = {'epoch': 0,'state_dict': model_ft.state_dict(), \n",
        "            'optimizer': 'optimizer_ft.state_dict()', \n",
        "              'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "create_directories(args.save_dir)\n",
        "full_model_path = args.save_dir+'/model_state_trained_labeled_5_epochs.tar'\n",
        "#full_model_path = saved_dir+'model_state.tar'\n",
        "torch.save(state, full_model_path)\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oXHJPntXKIP"
      },
      "source": [
        "# copy images_df and extra_df\n",
        "images_df_copy = images_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd13lSkpXKNB"
      },
      "source": [
        "# upate images_df\n",
        "\n",
        "new_extra = filter_extra_imgs()\n",
        "images_df = pd.concat((images_df_copy, new_extra), axis=0).reset_index( drop =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJe5ZcWJX_Aq",
        "outputId": "5e69ea5f-408e-48ad-f016-7704b184e18e"
      },
      "source": [
        "# train again with 5 ephoch\n",
        "\n",
        "for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "\n",
        "  train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "  train_dataset = extra_CassavaDataset(df_data=train, train_transform= train_trans,strong_trans=strong_trans)\n",
        "  valid_dataset = extra_CassavaDataset(df_data=val, train_transform= train_trans,strong_trans=strong_trans)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset, \n",
        "                            batch_size=args.batch_size, \n",
        "                            shuffle=True, \n",
        "                            num_workers=2,\n",
        "                            )\n",
        "  valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                            batch_size=args.batch_size, \n",
        "                            shuffle=False, \n",
        "                            num_workers=2,\n",
        "                            )\n",
        "\n",
        "  dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "  \n",
        "  dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "\n",
        "\n",
        "  model_ft = train_model(model_ft, criterion, \n",
        "                        optimizer_ft, \n",
        "                        exp_lr_scheduler, \n",
        "                        num_epochs=5,)\n",
        "\n",
        "  break\n",
        "\n",
        "# \n",
        "state = {'epoch': 0,'state_dict': model_ft.state_dict(), \n",
        "            'optimizer': 'optimizer_ft.state_dict()', \n",
        "              'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "create_directories(args.save_dir)\n",
        "full_model_path = args.save_dir+'/model_state_trained_fixmatch_5_epochs.tar'\n",
        "#full_model_path = saved_dir+'model_state.tar'\n",
        "torch.save(state, full_model_path)\n",
        "#\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 0.5139 Acc: 0.8070\n",
            "val Loss: 0.3866 Acc: 0.8602\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.4347 Acc: 0.8384\n",
            "val Loss: 0.3517 Acc: 0.8750\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.3737 Acc: 0.8625\n",
            "val Loss: 0.3677 Acc: 0.8657\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.3731 Acc: 0.8619\n",
            "val Loss: 0.3562 Acc: 0.8660\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.3725 Acc: 0.8639\n",
            "val Loss: 0.3420 Acc: 0.8731\n",
            "\n",
            "Training complete in 110m 14s\n",
            "Best val Acc: 0.875034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7G7F0b7X_Dw"
      },
      "source": [
        "# upate images_df again\n",
        "\n",
        "new_extra = filter_extra_imgs()\n",
        "images_df = pd.concat((images_df_copy, new_extra), axis=0).reset_index( drop =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJqF7cxeYbv7",
        "outputId": "6d975bf4-7ff3-40c5-c2ea-2fa46182f4a2"
      },
      "source": [
        "# train again with 5 ephoch\n",
        "\n",
        "for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "  train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "  train_dataset = extra_CassavaDataset(df_data=train, train_transform= train_trans,strong_trans=strong_trans)\n",
        "  valid_dataset = extra_CassavaDataset(df_data=val, train_transform= train_trans,strong_trans=strong_trans)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset, \n",
        "                            batch_size=args.batch_size, \n",
        "                            shuffle=True, \n",
        "                            num_workers=2,\n",
        "                            )\n",
        "  valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                            batch_size=args.batch_size, \n",
        "                            shuffle=False, \n",
        "                            num_workers=2,\n",
        "                            )\n",
        "\n",
        "  dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "  \n",
        "  dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "\n",
        "\n",
        "  model_ft = train_model(model_ft, criterion, \n",
        "                        optimizer_ft, \n",
        "                        exp_lr_scheduler, \n",
        "                        num_epochs=5,)\n",
        "\n",
        "  break\n",
        "\n",
        "# \n",
        "state = {'epoch': 0,'state_dict': model_ft.state_dict(), \n",
        "            'optimizer': 'optimizer_ft.state_dict()', \n",
        "              'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "create_directories(args.save_dir)\n",
        "full_model_path = args.save_dir+'/model_state_trained_fixmatch_10_epochs.tar'\n",
        "#full_model_path = saved_dir+'model_state.tar'\n",
        "torch.save(state, full_model_path)\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 0.3793 Acc: 0.8612\n",
            "val Loss: 0.2993 Acc: 0.8873\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.3661 Acc: 0.8650\n",
            "val Loss: 0.2936 Acc: 0.8964\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.3582 Acc: 0.8712\n",
            "val Loss: 0.2925 Acc: 0.8936\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.3547 Acc: 0.8688\n",
            "val Loss: 0.2921 Acc: 0.8947\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.3393 Acc: 0.8775\n",
            "val Loss: 0.2701 Acc: 0.9035\n",
            "\n",
            "Training complete in 110m 14s\n",
            "Best val Acc: 0.903509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnjjWRTMI7J-"
      },
      "source": [
        "# upate images_df again\n",
        "\n",
        "new_extra = filter_extra_imgs()\n",
        "images_df = pd.concat((images_df_copy, new_extra), axis=0).reset_index( drop =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO20EA_CI7Mt",
        "outputId": "3f8caa60-595f-4889-a493-379510b060b4"
      },
      "source": [
        "# train again with 5 ephoch\n",
        "\n",
        "for train_index, val_index in st_kfold.split(images_df['images'], images_df['labels']):\n",
        "  train, val = images_df.iloc[train_index], images_df.iloc[val_index]\n",
        "\n",
        "  train_dataset = extra_CassavaDataset(df_data=train, train_transform= train_trans,strong_trans=strong_trans)\n",
        "  valid_dataset = extra_CassavaDataset(df_data=val, train_transform= train_trans,strong_trans=strong_trans)\n",
        "\n",
        "  train_loader = DataLoader(dataset = train_dataset, \n",
        "                            batch_size=args.batch_size, \n",
        "                            shuffle=True, \n",
        "                            num_workers=2,\n",
        "                            )\n",
        "  valid_loader = DataLoader(dataset = valid_dataset, \n",
        "                            batch_size=args.batch_size, \n",
        "                            shuffle=False, \n",
        "                            num_workers=2,\n",
        "                            )\n",
        "\n",
        "  dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "  \n",
        "  dataset_sizes = {'train': len(train_dataset), 'val': len(valid_dataset)}\n",
        "\n",
        "\n",
        "  model_ft = train_model(model_ft, criterion, \n",
        "                        optimizer_ft, \n",
        "                        exp_lr_scheduler, \n",
        "                        num_epochs=5,)\n",
        "\n",
        "  break\n",
        "\n",
        "# \n",
        "state = {'epoch': 0,'state_dict': model_ft.state_dict(), \n",
        "            'optimizer': 'optimizer_ft.state_dict()', \n",
        "              'loss':'epoch_loss','valid_accuracy': 'best_acc'}\n",
        "create_directories(args.save_dir)\n",
        "full_model_path = args.save_dir+'/model_state_trained_fixmatch_15_epochs.tar'\n",
        "#full_model_path = saved_dir+'model_state.tar'\n",
        "torch.save(state, full_model_path)\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 0.3633 Acc: 0.8641\n",
            "val Loss: 0.2997 Acc: 0.8939\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.3548 Acc: 0.8697\n",
            "val Loss: 0.2968 Acc: 0.8972\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.3579 Acc: 0.8647\n",
            "val Loss: 0.2848 Acc: 0.8983\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.3546 Acc: 0.8687\n",
            "val Loss: 0.2996 Acc: 0.8926\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.3477 Acc: 0.8708\n",
            "val Loss: 0.3160 Acc: 0.8854\n",
            "\n",
            "Training complete in 108m 58s\n",
            "Best val Acc: 0.898328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZqglplkNJZe",
        "outputId": "bd7847f1-af24-4fcd-a1e7-80f76d0c7799"
      },
      "source": [
        "full_model_path = args.save_dir+'model_state_trained_fixmatch_10_epochs.tar'\n",
        "final_model, optimizer, _ = load_checkpoint(model_ft, \n",
        "                                            optimizer_ft, \n",
        "                                            filename=full_model_path,\n",
        "                                            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> loading checkpoint '/content/drive/MyDrive/kaggle/cassave/model_state_trained_fixmatch_10_epochs.tar'\n",
            "=> loaded checkpoint '/content/drive/MyDrive/kaggle/cassave/model_state_trained_fixmatch_10_epochs.tar' (epoch 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxootOnLJHN3",
        "outputId": "53f05bf9-71cc-49e7-f3bf-0e6af9a302f7"
      },
      "source": [
        "predict_with_tta(model=final_model,\n",
        "              transform=test_trans, \n",
        "              test_data=test_data, \n",
        "              num_of_tta=10,\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inferencing with 10 TTA ...\n",
            "Training complete in 24m 58s\n"
          ]
        }
      ]
    }
  ]
}